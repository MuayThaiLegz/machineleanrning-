{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67739a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85126122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from pylab import mpl, plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers , models\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6183325",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Chapter 5 Deep learning for computer vison:\n",
    "\n",
    "Introduction to convnets:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0ab527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a small convet\n",
    "\n",
    "\n",
    "conv_model = models.Sequential()\n",
    "\n",
    "conv_model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "conv_model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "conv_model.add(layers.Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26069d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Importantly,convnet takes as input tensors of shape (image_height, image_width, image_channels).\n",
    "   (Not including batch dim)\n",
    "    \n",
    "Displaying architercture of the convnet so far we see that the output of every Conv2d and Maxpool\n",
    "is a 3d tensor of shape (height, width, channels) width and height tend to shrink as you go\n",
    "deeper into the network. Num of chanels is controlled by the first argument passed to the\n",
    "Conv2d layers 32 or 64\n",
    "\"\"\"\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65100a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The nest step is to feed the last outpur tensor of shape (3, 3, 64)) into a densely connected \n",
    "classifier networks with a stack of dense layers/ These classifiers process 1d vectors\n",
    "Where the curretn output is a 3d tensor. first we have to flatten then add a few dense layers\n",
    "\"\"\"\n",
    "\n",
    "conv_model.add(layers.Flatten())\n",
    "\n",
    "conv_model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "conv_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ffe13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29226d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the convnet on MNIST images\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2f2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f962273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.1761 - acc: 0.9441\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 0.0470 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.0328 - acc: 0.9901\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.0251 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 17s 292us/sample - loss: 0.0204 - acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18808e9a908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "conv_model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "conv_model.fit(train_images, train_labels, epochs=5, batch_size=65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2390f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 96us/sample - loss: 0.0307 - acc: 0.9908\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = conv_model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a4581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
