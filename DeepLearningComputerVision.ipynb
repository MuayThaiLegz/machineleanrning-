{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c67739a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85126122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from pylab import mpl, plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers , models\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6183325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Chapter 5 Deep learning for computer vison:\\n\\nIntroduction to convnets:\\n\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Chapter 5 Deep learning for computer vison:\n",
    "\n",
    "Introduction to convnets:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f0ab527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a small convet\n",
    "\n",
    "\n",
    "conv_model = models.Sequential()\n",
    "\n",
    "conv_model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "conv_model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "conv_model.add(layers.Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26069d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Importantly,convnet takes as input tensors of shape (image_height, image_width, image_channels).\n",
    "   (Not including batch dim)\n",
    "    \n",
    "Displaying architercture of the convnet so far we see that the output of every Conv2d and Maxpool\n",
    "is a 3d tensor of shape (height, width, channels) width and height tend to shrink as you go\n",
    "deeper into the network. Num of chanels is controlled by the first argument passed to the\n",
    "Conv2d layers 32 or 64\n",
    "\"\"\"\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65100a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The nest step is to feed the last outpur tensor of shape (3, 3, 64)) into a densely connected \n",
    "classifier networks with a stack of dense layers/ These classifiers process 1d vectors\n",
    "Where the curretn output is a 3d tensor. first we have to flatten then add a few dense layers\n",
    "\"\"\"\n",
    "\n",
    "conv_model.add(layers.Flatten())\n",
    "\n",
    "conv_model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "conv_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09ffe13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29226d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the convnet on MNIST images\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba2f2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f962273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 21s 350us/sample - loss: 0.1758 - acc: 0.9446\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.0484 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 21s 353us/sample - loss: 0.0326 - acc: 0.9897 - loss: 0.0326 - acc: 0.\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 22s 362us/sample - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.0190 - acc: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad5493d748>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "conv_model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "conv_model.fit(train_images, train_labels, epochs=5, batch_size=65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2390f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 129us/sample - loss: 0.0284 - acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = conv_model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f355100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying images to training, validation, and test directories\n",
    "\n",
    "import os, shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1864998c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '               '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_65300/3805732667.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"               \"\u001b[0m    \u001b[1;31m# Directory where dataset you'll store your smaller dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[1;31m# Directories for the training, validation, and test splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '               '"
     ]
    }
   ],
   "source": [
    "original_dataset_dir = \"               \"   # Path to directory where dataset was uncompressed\n",
    "\n",
    "base_dir = \"               \"    # Directory where dataset you'll store your smaller dataset\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "                                # Directories for the training, validation, and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join('base_dir', 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class1_dir = os.path.join(train_dir, 'class1') # Directory with class1 pictures \n",
    "os.mkdir(train_class1_dir)\n",
    "\n",
    "\n",
    "train_class2_dir = os.path.join(train_dir, 'class2') # Directory with class2 pictures\n",
    "os.mkdir(train_class2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_class1_dir = os.path.join(validation_dir, 'class1 ')\n",
    "os.mkdir(validation_class1_dir)\n",
    "                                # Directories with validation data.\n",
    "validation_class2_dir = os.path.join(validation_dir, 'class2')\n",
    "os.mkdir(validation_class2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class1_dir = os.path.join(test_dir, \"class1\")\n",
    "os.mkdir(test_class1_dir)\n",
    "                        # Direcotries with test data.\n",
    "test_class2_dir = os.path.join(test_dir, 'class2')\n",
    "os.mkdir(test_class2_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['class1.{}.jpg'.format(i) for i in range(5)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst - os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['class1.{}.jpg'.format(i) for i in range (5, 10)]\n",
    "for fname i fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_class1_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['class1.{}.jpg'.format(i) for i in range (10, 25)]\n",
    "for fname i fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_class1_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96617c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['class2.{}.jpg'.format(i) for i in range(5)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst - os.path.join(validation_class2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['class2.{}.jpg'.format(i) for i in range (5, 10)]\n",
    "for fname i fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_class2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['class2.{}.jpg'.format(i) for i in range (10, 25)]\n",
    "for fname i fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_class2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a sanity check, let's count how many pictures are in each training splits\n",
    "# (train/validation/test)\n",
    "\n",
    "\n",
    "print('Total traing class1 images:', len(os.listdir(train_class1_dir)))\n",
    "\n",
    "print('Total traing class2 images:', len(os.listdir(train_class2_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total validation class1 images:', len(os.listdir(validation_class1_dir)))\n",
    "\n",
    "print('Total validation class2 images:', len(os.listdir(validation_class2_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110970e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total test class1 images:', len(os.listdir(test_class1_dir)))\n",
    "\n",
    "print('Total test class2 images:', len(os.listdir(test_class2_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54e6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building your network\n",
    "\"\"\"\n",
    "Here dealing with bigger images and a more complex problem, you'll make your natwork larger,\n",
    "accordingle: it will have one more Conv2D + MaxPooling2D stage. This serves both to augment the \n",
    "capacity of the network and to futher reduce the size of the feature maps so they aren't overly \n",
    "large when Flatten layer is reached. \n",
    "Staring with input_size = 150 x 150, you end up with feature maps of size 7 x 7\n",
    "just before the Flatten Layer.\n",
    "\n",
    "\n",
    "NOTE\n",
    "The depth of the feature maps progressively increases in the network (from 32 to 128), \n",
    "the size of the feature maps decreases from (148 x 148 to 7 x 7)\n",
    "\n",
    "Here we use attack a binary classification problem. We end up woth a network with a single unit\n",
    "(a Dense layer of size 1) and a sigmoid activation. Thus unit ecodes the probability that \n",
    "the natwork is looking at once class or another.\n",
    "\"\"\"\n",
    "from tensorflow.keras import layers,models, optimizers\n",
    "\n",
    "real_model = models.Sequential()\n",
    "\n",
    "real_model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "real_model.add(layers.MaxPool2D((2, 2)))\n",
    "\n",
    "real_model.add(layers.Conv2D(64, (3, 3),activation = 'relu')\n",
    "\n",
    "real_model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "real_model.add(layers.Conv2D(128, (3, 3),activation = 'relu')\n",
    "    \n",
    "real_model.add(layers.MaxPool2D((2,2)))\n",
    "   \n",
    "real_model.add(layers.Conv2D(128, (3, 3),activation = 'relu')\n",
    "    \n",
    "real_model.add(layers.MaxPool2D((2, 2)))\n",
    "               \n",
    "real_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer = optimizers('rmsprop'),\n",
    "                  metrics=['acc'])\n",
    "               \n",
    "# Data preprocessing Data should be farmatted into appropriately preprocessed\n",
    "# floating point tnesors before neing fed into the network. \n",
    "# Currently, data sits on a drive as jpeg files, the steps for getting it into network are:\n",
    "               # Read the pic files\n",
    "               \n",
    "               # Decode the jpeg content to RGB frids of pixels\n",
    "               \n",
    "               # Convert these into floating-point tensors\n",
    "               \n",
    "               # rescale the pixels values (betwwen 0 and 255) to the [0, 1] interval\n",
    "                #   (as you know, NN prefer to deal with small input vals) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keras has module with image-processing helper tools, loactes at keras.preprocessing.image. \n",
    "The class ImageDataGenerator. Which lets you quickly set up python genarators that can\n",
    "automatically  turn image files on disk into batches of preprocessed tensors.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd27620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08248057",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64770ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Python generators\n",
    "'''\n",
    "A python generator is an object that acts as an iterator: it's an object you can use with the \n",
    "for _ in operator. Generators are bulit using the yield operator \n",
    "'''\n",
    "\n",
    "def generator():\n",
    "    i = 0 \n",
    "    while True:\n",
    "        i += 1\n",
    "        yield 1\n",
    "\n",
    "for item in generator():\n",
    "    print(item)\n",
    "    if item < 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE that the generator yields these batches indefinitely:\n",
    "it loops endlessly over the images in the target folger.\n",
    "For this reason, you need to break the iteration loop at some point:\n",
    "\"\"\"\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The fit_generator method, expects as its first argument a python generator that will yield batches \n",
    "of inputs and targets indefinitely. The Keras model needs to know how many samples to draw from the\n",
    "generator before declaring an epoch over. This is the role of the steps_per_epoch arg. You can pass validation data\n",
    "This arguments is allowed to be a data generator or a tuple of Numpy arrays. If a generator is passed\n",
    "the this generator is expected to yield batches of validation data endlessly: thus you should have\n",
    "also epecify the validation_steps atg. tells the prcess how many batches to draw from the validation\n",
    "generator for evaluation. \n",
    "\"\"\"\n",
    "\n",
    "history = real_model.fit_generator(\n",
    "    train_datagen, steps_per_epoch = 100, epochs = 30,\n",
    "    validation_data = valtiodation_generator, validation_steps=50)\n",
    "\n",
    "\n",
    "# Its goood prectice to always save your models after trainging \n",
    "\n",
    "# real_model('class1_and_class2_1.h5')\n",
    "\n",
    "\n",
    "# Displaying cruves of loss and accuracy during training\n",
    "\n",
    "import matplotlib as plt \n",
    "\n",
    "acc = history.history['acc']\n",
    "\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epaocs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa929c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "522b3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Data augmentation takes the approach of genarating more training data from existing training\n",
    "samples, by sugmenting the samples via a number of random tranformations that yield\n",
    "believable-looking images. The goal is that at training time, your model will never see the exact\n",
    "same picture twice. Helping expose the model to more aspects of the data and genaralize better.\n",
    "\n",
    "\n",
    "# Setting up a data augmentation configuration via ImageDataGenerator\n",
    "\"\"\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some randomly augmented training images \n",
    "\n",
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "\n",
    "fnames = [os.path.join(train_class1_dir, fname) for\n",
    "         fname in os.listdir(train_class1_dir)]\n",
    "\n",
    "img_path = fnames[3]  # Chooses one image to augment\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))  # Reads the image and resizes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcaf7805",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_65300/2015991739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "x = image.img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0 \n",
    "\n",
    "for batch in dategen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1aa156fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a new convnet that includes dropout\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3),\n",
    "                        activation='relu')\n",
    "          \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),\n",
    "                        activation='relu')          \n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),\n",
    "                        activation='relu')\n",
    "          \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "          \n",
    "model.add(layers.Flatten())\n",
    "          \n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "          \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = optimizers('rmsprop'),\n",
    "             metrics = ['acc'])\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959cc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the convet using data-augmentaion generators \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "validation_genarator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7da6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Using pretrained network:\n",
    "The convolutinal base of the VGG16 network to extract interesting features from the images, \n",
    "and train a classifier on top of these features.\n",
    "\n",
    "\n",
    "# Instatiating the VGG16 convolutional base \n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top = False,\n",
    "                 input_shape=(150, 150, 3))\n",
    "\n",
    "conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3e132ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast feature extraction without data augmentation \n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/Users/fchollet/Downloads/class1_and_class2'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_feature(directory, sample_count):\n",
    "    feature = np.zeros(shape = (sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150,150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0 \n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        feature_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1 ) * batch_size] = feature_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1 \n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "        return features, labels\n",
    "    \n",
    "train_features, train_labels = extract_feature(train_dir, 2000)\n",
    "\n",
    "validation_features, validation_labels = extract_feature(validation_dir, 1000)\n",
    "\n",
    "test_features, test_labels = extract_feature(test_dir, 1000)\n",
    "\n",
    "\n",
    "train_fea = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "\n",
    "validation_fea = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "\n",
    "test_fea = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "\n",
    "extract_model = models.Sequential()\n",
    "\n",
    "extract_model.add(layers.Dense(256, activation='relu', input_dim = 4 ( 4 * 512)))\n",
    "\n",
    "extract_model.add(layers.Dropout(0.5))\n",
    "\n",
    "extract_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "extract_model.compile(optimizers='rsmprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "history = extract_model.fit(train_features, train_labels,\n",
    "                            epochs=30, batch_size=20,\n",
    "                            validation_data=(validation_features, validation_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sthe results \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_loss']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing feature extraction using augmentaion during training :\n",
    "##### I YOU CAN TURN ON YOUR GPU TECH ABOVE IS THE WAY TO GO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
