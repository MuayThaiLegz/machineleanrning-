{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L28Do23GHAgl"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import mutual_info_classif \n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import feature_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "#import shap\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "if gpu_devices:\n",
        "    print('Using GPU')\n",
        "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
        "else:\n",
        "    print('Using CPU')\n",
        "    \n",
        "    \n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "\n",
        "Shutdown_Physiologic = pd.read_csv(\"Shutdown_Physiologic.csv\").drop('Unnamed: 0', axis=1).set_index(['case_id','phenotype'])\n",
        "\n",
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "pheno_type_cat = Shutdown_Physiologic[['pheno']]\n",
        "pheno_type_cat_1hot = cat_encoder.fit_transform(pheno_type_cat)\n",
        "Shutdown_Physiologic['pheno'] = pheno_type_cat_1hot\n",
        "\n",
        "#scaled_Shutdown_Physiologic = (Shutdown_Physiologic - Shutdown_Physiologic.mean()) / Shutdown_Physiologic.std()\n",
        "sklr = StandardScaler()\n",
        "\n",
        "y = Shutdown_Physiologic['pheno']\n",
        "y = y.astype(int)\n",
        "\n",
        "X_to_drop = Shutdown_Physiologic.drop(\"pheno\", axis=1)\n",
        "temp_X = sklr.fit_transform(X_to_drop)\n",
        "X = pd.DataFrame(temp_X,columns=X_to_drop.columns, index = X_to_drop.index)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)\n",
        "\n",
        "feats_list = []\n",
        "\n",
        "test_size=.50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTXPTTuLHNQ5",
        "outputId": "f59af05c-8a7b-41ab-b789-06c5fadda642"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gs = rfxgb_clf_random.fit(X_train, y_train)\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)\n",
        "\n",
        "clf = gs.best_estimator_\n",
        "print('Test accuracy: %.3f' % clf.score(X_test, y_test))\n",
        "pred = clf.predict(X_test)\n",
        "score = accuracy_score(y_test, pred) \n",
        "cm = confusion_matrix(y_test, pred)\n",
        "cr = classification_report(y_test, pred)\n",
        "\n",
        "print(\"-\"*90)\n",
        "print(\"Accuracy Score: {} With Classifier: {}\".format(score, clf))\n",
        "print(\"-\"*90)\n",
        "print(\"printing classification report to console along with dataset and dataset number: \")\n",
        "print(\"-\"*90)\n",
        "print(\"CLASS_REPORT: {}\".format(cr))\n",
        "print(\"-\"*90)"
      ],
      "metadata": {
        "id": "uqrUYWkU1Hkf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FkpMahQ-1Ge_"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8uQN-09VruL"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "GridSearchCV_Parameters_df = pd.DataFrame(columns=['Classifier', 'BestScore', 'BestEstimator', 'Prediction', 'Accuracy_score'])\n",
        "\n",
        "names = [\n",
        "    \"XGB\",\n",
        "    \"ADABoost\",\n",
        "    \"SVC\",\n",
        "    \"LogReg\",    \n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "]\n",
        "\n",
        "\n",
        "param_grid = [ \n",
        "    {'learning_rate': [0.001, 0.01, .1], 'booster':['gbtree', 'gblinear', 'dart'], 'gamma':[0.5, 1.0, 1.5]},\n",
        "    {'n_estimators': [25, 75, 110], 'learning_rate':[0.5, 1.0, 1.5],'algorithm':['SAMME', 'SAMME.R']},\n",
        "    {'C': [0.5, 1.0, 1.5], 'kernel': ['poly', 'rbf', 'sigmoid'], 'max_iter':[500, 1250, 2000]},\n",
        "    {'C': [0.5, 1.0, 1.5], 'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
        "    {'n_estimators': [50, 125, 250],'criterion': ['gini', 'entropy', 'log_loss'], 'max_depth': [None, 5, 20]},\n",
        "    {'hidden_layer_sizes': [50, 100, 125], 'activation': ['identity', 'logistic', 'relu'], 'alpha': [.0001, .001, .01]},\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "classifiers = [\n",
        "    XGBClassifier(random_state=42),\n",
        "    AdaBoostClassifier(random_state=42),\n",
        "    SVC(random_state=1),\n",
        "    LogisticRegression(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    MLPClassifier(random_state=1),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.02, random_state=12)\n",
        "\n",
        "for classifiers, param_grid in zip(classifiers, param_grid):\n",
        "    \n",
        "    grid_search = GridSearchCV(classifiers, cv=5,param_grid=param_grid , scoring='accuracy', return_train_score=True)\n",
        "\n",
        "  \n",
        "    grid_search.fit(X_train, y_train)\n",
        "    Prediction = []\n",
        "    Accuracy_s = []\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "    Prediction.append(y_pred)\n",
        "    Accuracy_s.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "    #score = grid_search.score(X_test, y_test)\n",
        "    #print(\"Test Score: {} With Classifier: {}\".format(score, clf))\n",
        "    # Get the classifier's parameters\n",
        "    params = classifiers.get_params()\n",
        "    # Add the classifier name and parameters to the dataframe\n",
        "    GridSearchCV_Parameters_df = GridSearchCV_Parameters_df.append(\n",
        "        {'Classifier': classifiers.__class__.__name__,  \n",
        "         'BestScore': grid_search.best_score_,\n",
        "         'BestEstimator':grid_search.best_estimator_,\n",
        "         'Prediction': Prediction,\n",
        "         'Accuracy_score': Accuracy_s}, ignore_index=True)\n",
        "\n",
        "    \n",
        "    #accuracy_scoreDict['Accuracy Score'].append(score) \n",
        "    print(\"-\"*90)\n",
        "    print(f\"Best hyperparameters for {classifiers.__class__.__name__}: {grid_search.best_params_}\")\n",
        "    print(\"-\"*90)\n",
        "    print(f\"Best score for {classifiers.__class__.__name__}: {grid_search.best_score_:.3f}\")\n",
        "    print(\"-\"*90)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vci8IKk3o4PN",
        "outputId": "561044fd-6649-420b-8b11-bfa952b08027"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for XGBClassifier: {'booster': 'gblinear', 'gamma': 0.5, 'learning_rate': 0.01}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for XGBClassifier: 0.620\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for AdaBoostClassifier: {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 110}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for AdaBoostClassifier: 0.680\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for SVC: {'C': 1.5, 'kernel': 'rbf', 'max_iter': 500}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for SVC: 0.660\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for LogisticRegression: {'C': 0.5, 'penalty': 'none'}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for LogisticRegression: 0.680\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for RandomForestClassifier: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 250}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for RandomForestClassifier: 0.620\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Best hyperparameters for MLPClassifier: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 100}\n",
            "------------------------------------------------------------------------------------------\n",
            "Best score for MLPClassifier: 0.620\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GridSearchCV_Parameters_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "YoWMzlFX5xeZ",
        "outputId": "09874816-eb08-49ae-c917-3bb604becfb8"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Classifier  BestScore  \\\n",
              "0           XGBClassifier       0.62   \n",
              "1      AdaBoostClassifier       0.68   \n",
              "2                     SVC       0.66   \n",
              "3      LogisticRegression       0.68   \n",
              "4  RandomForestClassifier       0.62   \n",
              "5           MLPClassifier       0.62   \n",
              "\n",
              "                                       BestEstimator Prediction Accuracy_score  \n",
              "0  XGBClassifier(booster='gblinear', gamma=0.5, l...   [[0, 1]]          [0.5]  \n",
              "1  (DecisionTreeClassifier(max_depth=1, random_st...   [[1, 1]]          [1.0]  \n",
              "2           SVC(C=1.5, max_iter=500, random_state=1)   [[0, 1]]          [0.5]  \n",
              "3  LogisticRegression(C=0.5, penalty='none', rand...   [[1, 1]]          [1.0]  \n",
              "4  (DecisionTreeClassifier(criterion='entropy', m...   [[1, 1]]          [1.0]  \n",
              "5  MLPClassifier(hidden_layer_sizes=100, random_s...   [[1, 1]]          [1.0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70642a9a-46c5-4a30-8258-74c798f3296a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>BestScore</th>\n",
              "      <th>BestEstimator</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Accuracy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.62</td>\n",
              "      <td>XGBClassifier(booster='gblinear', gamma=0.5, l...</td>\n",
              "      <td>[[0, 1]]</td>\n",
              "      <td>[0.5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.68</td>\n",
              "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
              "      <td>[[1, 1]]</td>\n",
              "      <td>[1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.66</td>\n",
              "      <td>SVC(C=1.5, max_iter=500, random_state=1)</td>\n",
              "      <td>[[0, 1]]</td>\n",
              "      <td>[0.5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.68</td>\n",
              "      <td>LogisticRegression(C=0.5, penalty='none', rand...</td>\n",
              "      <td>[[1, 1]]</td>\n",
              "      <td>[1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.62</td>\n",
              "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
              "      <td>[[1, 1]]</td>\n",
              "      <td>[1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>0.62</td>\n",
              "      <td>MLPClassifier(hidden_layer_sizes=100, random_s...</td>\n",
              "      <td>[[1, 1]]</td>\n",
              "      <td>[1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70642a9a-46c5-4a30-8258-74c798f3296a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70642a9a-46c5-4a30-8258-74c798f3296a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70642a9a-46c5-4a30-8258-74c798f3296a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCUXFq5hjDv8"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4D-H5nefgxCr"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestnames = [\n",
        "    \"XGB\",\n",
        "    \"ADABoost\",\n",
        "    \"SVC\",\n",
        "    \"LogReg\",    \n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "]\n",
        "bestclsresults_df = pd.DataFrame(columns=['Classifier', 'Accuracy_score', 'Prediction'])\n",
        "\n",
        "\n",
        "\n",
        "bestcls = [\n",
        "    XGBClassifier(booster='gblinear', gamma=1.5, learning_rate=0.01, random_state=42)\t,\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42)\t,\n",
        "    SVC(C=1.5, kernel='sigmoid', max_iter=500, random_state=1),\n",
        "    LogisticRegression(C=0.5, random_state=1),\n",
        "    RandomForestClassifier(criterion='entropy', n_estimators=125, random_state=1),\t\n",
        "    MLPClassifier(activation='logistic', hidden_layer_sizes=100, random_state=1),\t\n",
        "]\n",
        "\n",
        "  \n",
        "for bestcls, bestnames  in zip(bestcls, bestnames ):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=12)\n",
        "  Prediction = []\n",
        "  Accuracy_=  []\n",
        "  bestcls.fit(X_train, y_train)\n",
        "  y_pred = bestcls.predict(X_test)\n",
        "  print(y_pred)\n",
        "  Prediction.append(y_pred)\n",
        "  print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "  Accuracy_s.append(accuracy_score(y_test, y_pred))\n",
        "  \n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c51sJh97jDtC",
        "outputId": "59c06c43-380a-4ca0-d2db-37a519ba4ced"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 1 0 0 1 1]\n",
            "0.5454545454545454\n",
            "[0 1 1 0 1 0 1 0 1 1 1]\n",
            "0.6363636363636364\n",
            "[0 1 0 0 1 0 1 0 0 1 1]\n",
            "0.6363636363636364\n",
            "[0 1 0 0 1 0 1 0 0 1 1]\n",
            "0.6363636363636364\n",
            "[1 1 0 0 1 1 1 0 0 1 1]\n",
            "0.6363636363636364\n",
            "[1 1 0 0 1 1 1 0 0 1 1]\n",
            "0.6363636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestclsresults_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "e-bfjYYxjDqb",
        "outputId": "65bd9751-7cb4-4c07-9611-697c8bdb69ed"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Classifier, Accuracy_score, Prediction]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1e7294d-35a4-465c-8005-351456f59d78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy_score</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1e7294d-35a4-465c-8005-351456f59d78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1e7294d-35a4-465c-8005-351456f59d78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1e7294d-35a4-465c-8005-351456f59d78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvGMb7Gsuz24"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "alpha, learning_rate = [float(x) for x in np.linspace(0.0001, 0.5, num = 10)], [float(x) for x in np.linspace(0.0001, 0.5, num = 10)]\n",
        "booster = ['gbtree', 'gblinear', 'dart']\n",
        "C, gamma = [float(x) for x in np.linspace(0.0001, 2.0, num = 10)], [float(x) for x in np.linspace(0.0001, 2.0, num = 10)]\n",
        "iterations, n_estimators = [int(x) for x in np.linspace(start = 15, stop = 250, num = 10)],  [int(x) for x in np.linspace(start = 15, stop = 250, num = 10)]\n",
        "algorithm = ['SAMME', 'SAMME.R']\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "max_iter = [int(x) for x in np.linspace(start = 100 , stop = 450, num = 10)]\n",
        "penalty = ['l1', 'l2', 'elasticnet']\n",
        "# Number of features to consider at every split\n",
        "criterion = ['gini', 'entropy', 'log_loss']\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(2, 50, num = 10)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "hidden_layer_sizes = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
        "activation =  ['identity', 'logistic', 'relu']\n",
        "\n",
        "\n",
        "RandomizedSearchCV_Parameters_df = pd.DataFrame(columns=['Classifier', 'BestScore', 'BestEstimator'])\n",
        "\n",
        "random_grid = [ \n",
        "    {'learning_rate': learning_rate, 'booster':booster, 'gamma':gamma},\n",
        "    {'n_estimators': n_estimators, 'learning_rate':learning_rate,'algorithm':algorithm},\n",
        "   \n",
        "    {'C': C, 'kernel': kernel, 'max_iter': max_iter},\n",
        "    {'C': C, 'penalty': penalty},\n",
        "    {'n_estimators': n_estimators,'criterion': criterion, 'max_depth': max_depth},\n",
        "    {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'alpha': alpha},\n",
        "    ]\n",
        "\n",
        "classifiers = [\n",
        "    XGBClassifier(random_state=42),\n",
        "    AdaBoostClassifier(random_state=42),\n",
        "    SVC(random_state=1),\n",
        "    LogisticRegression(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    MLPClassifier(random_state=1),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "for classifiers, random_grid in zip(classifiers, random_grid):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=12)\n",
        "\n",
        "    rand_search = RandomizedSearchCV(classifiers, cv=5,param_distributions=random_grid , scoring='accuracy', return_train_score=True,random_state=12)\n",
        "\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    params = classifiers.get_params()\n",
        "\n",
        "    RandomizedSearchCV_Parameters_df = RandomizedSearchCV_Parameters_df.append(\n",
        "        {'Classifier': classifiers.__class__.__name__, \n",
        "        'BestScore': rand_search.best_score_,\n",
        "         'BestEstimator':rand_search.best_estimator_}, ignore_index=True\n",
        "        )\n",
        "    #Rand_SearchCVresults['BestEstimator'].append(rand_search.best_estimator_)\n",
        "    print(f\"Best hyperparameters for {classifiers.__class__.__name__}: {rand_search.best_params_}\")\n",
        "    print(f\"Best score for {classifiers.__class__.__name__}: {rand_search.best_score_:.3f}\")\n",
        "\n",
        "RandomizedSearchCV_Parameters_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "FDxVLbqsTzQC",
        "outputId": "ea86c28d-744a-4cdc-9b0c-ba32d88c7aa4"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters for XGBClassifier: {'learning_rate': 0.0001, 'gamma': 2.0, 'booster': 'gblinear'}\n",
            "Best score for XGBClassifier: 0.767\n",
            "Best hyperparameters for AdaBoostClassifier: {'n_estimators': 41, 'learning_rate': 0.11118888888888889, 'algorithm': 'SAMME'}\n",
            "Best score for AdaBoostClassifier: 0.733\n",
            "Best hyperparameters for SVC: {'max_iter': 138, 'kernel': 'sigmoid', 'C': 1.5555777777777777}\n",
            "Best score for SVC: 0.767\n",
            "Best hyperparameters for LogisticRegression: {'penalty': 'l2', 'C': 0.4445222222222222}\n",
            "Best score for LogisticRegression: 0.733\n",
            "Best hyperparameters for RandomForestClassifier: {'n_estimators': 41, 'max_depth': 2, 'criterion': 'gini'}\n",
            "Best score for RandomForestClassifier: 0.807\n",
            "Best hyperparameters for MLPClassifier: {'hidden_layer_sizes': 23, 'alpha': 0.11118888888888889, 'activation': 'relu'}\n",
            "Best score for MLPClassifier: 0.800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Classifier  BestScore  \\\n",
              "0           XGBClassifier   0.766667   \n",
              "1      AdaBoostClassifier   0.733333   \n",
              "2                     SVC   0.766667   \n",
              "3      LogisticRegression   0.733333   \n",
              "4  RandomForestClassifier   0.806667   \n",
              "5           MLPClassifier   0.800000   \n",
              "\n",
              "                                       BestEstimator  \n",
              "0  XGBClassifier(booster='gblinear', gamma=2.0, l...  \n",
              "1  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
              "2  SVC(C=1.5555777777777777, kernel='sigmoid', ma...  \n",
              "3  LogisticRegression(C=0.4445222222222222, rando...  \n",
              "4  (DecisionTreeClassifier(max_depth=2, max_featu...  \n",
              "5  MLPClassifier(alpha=0.11118888888888889, hidde...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f1789ff-f652-4c67-b35a-2454ea72ea81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>BestScore</th>\n",
              "      <th>BestEstimator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>XGBClassifier(booster='gblinear', gamma=2.0, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>SVC(C=1.5555777777777777, kernel='sigmoid', ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>LogisticRegression(C=0.4445222222222222, rando...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.806667</td>\n",
              "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>MLPClassifier(alpha=0.11118888888888889, hidde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f1789ff-f652-4c67-b35a-2454ea72ea81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f1789ff-f652-4c67-b35a-2454ea72ea81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f1789ff-f652-4c67-b35a-2454ea72ea81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "BestRandresults = {'Classifier': [],\"Accuracy Score\": []}#, 'Datasetfrom':[]}\n",
        "\n",
        "best_rand_cls = [\n",
        "    XGBClassifier(booster='dart', gamma=0.2222311111111111, learning_rate=0.3000066666666667, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1000088888888889, n_estimators=36, random_state=42),\n",
        "    SVC(C=1.5555577777777776, kernel='sigmoid', max_iter=400, random_state=1),\n",
        "    LogisticRegression(C=0.4444522222222222, random_state=1),\n",
        "    RandomForestClassifier(max_depth=2, n_estimators=36, random_state=1),\n",
        "    MLPClassifier(activation='logistic',alpha=0.055564444444444444, hidden_layer_sizes=101, random_state=1)\t\t\t\t\t\n",
        "]\n",
        "\n",
        "\n",
        "for clf, name in zip(best_rand_cls, names):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.20)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "  pred = clf.predict(X_test)\n",
        "  score = accuracy_score(y_test, pred) \n",
        "  cm = confusion_matrix(y_test, pred)\n",
        "  cr = classification_report(y_test, pred)\n",
        "\n",
        "  BestRandresults['Classifier'].append(name)\n",
        "  BestRandresults['Accuracy Score'].append(score)\n",
        "  #BestRandresults['Datasetfrom'].append(ds_cnt)\n",
        "    \n",
        "\n",
        "  print(\"-\"*90)\n",
        "  print(\"Test Score: {} With Classifier: {}\".format(score, clf))\n",
        "  print(\"-\"*90)\n",
        "  print(\"printing classification report to console along with dataset and dataset number: \")\n",
        "  #print(\"{} : {}\".format(ds, ds_cnt))\n",
        "\n",
        "  print(\"-\"*90)\n",
        "  print(\"CLASS_REPORT: {}\".format(cr))\n",
        "  print(\"-\"*90) \n",
        "\n",
        "Randperformance_df = pd.DataFrame(BestRandresults)          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKB70M9oTzLA",
        "outputId": "dfd5376a-38ef-42db-dde8-ccd903a11ffa"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.5454545454545454 With Classifier: XGBClassifier(booster='dart', gamma=0.2222311111111111,\n",
            "              learning_rate=0.3000066666666667, random_state=42)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.75      0.55         4\n",
            "           1       0.75      0.43      0.55         7\n",
            "\n",
            "    accuracy                           0.55        11\n",
            "   macro avg       0.59      0.59      0.55        11\n",
            "weighted avg       0.63      0.55      0.55        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.6363636363636364 With Classifier: AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1000088888888889,\n",
            "                   n_estimators=36, random_state=42)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.75      0.60         4\n",
            "           1       0.80      0.57      0.67         7\n",
            "\n",
            "    accuracy                           0.64        11\n",
            "   macro avg       0.65      0.66      0.63        11\n",
            "weighted avg       0.69      0.64      0.64        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.5454545454545454 With Classifier: SVC(C=1.5555577777777776, kernel='sigmoid', max_iter=400, random_state=1)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44         4\n",
            "           1       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.55        11\n",
            "   macro avg       0.53      0.54      0.53        11\n",
            "weighted avg       0.57      0.55      0.55        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.5454545454545454 With Classifier: LogisticRegression(C=0.4444522222222222, random_state=1)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44         4\n",
            "           1       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.55        11\n",
            "   macro avg       0.53      0.54      0.53        11\n",
            "weighted avg       0.57      0.55      0.55        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.45454545454545453 With Classifier: RandomForestClassifier(max_depth=2, n_estimators=36, random_state=1)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.75      0.50         4\n",
            "           1       0.67      0.29      0.40         7\n",
            "\n",
            "    accuracy                           0.45        11\n",
            "   macro avg       0.52      0.52      0.45        11\n",
            "weighted avg       0.56      0.45      0.44        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Test Score: 0.45454545454545453 With Classifier: MLPClassifier(activation='logistic', alpha=0.055564444444444444,\n",
            "              hidden_layer_sizes=101, random_state=1)\n",
            "------------------------------------------------------------------------------------------\n",
            "printing classification report to console along with dataset and dataset number: \n",
            "------------------------------------------------------------------------------------------\n",
            "CLASS_REPORT:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         4\n",
            "           1       0.60      0.43      0.50         7\n",
            "\n",
            "    accuracy                           0.45        11\n",
            "   macro avg       0.47      0.46      0.45        11\n",
            "weighted avg       0.50      0.45      0.46        11\n",
            "\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPN6ypaOUg-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [\n",
        "    XGBClassifier(random_state=42),\n",
        "    AdaBoostClassifier(random_state=42),\n",
        "    SVC(random_state=1),\n",
        "    LogisticRegression(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    MLPClassifier(random_state=1),\n",
        "]\n",
        "\n",
        "bestcls = [\n",
        "    XGBClassifier(booster='gblinear', gamma=1.5, learning_rate=0.01, random_state=42)\t,\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42)\t,\n",
        "    SVC(C=1.5, kernel='sigmoid', max_iter=500, random_state=1),\n",
        "    LogisticRegression(C=0.5, random_state=1),\n",
        "    RandomForestClassifier(criterion='entropy', n_estimators=125, random_state=1),\t\n",
        "    MLPClassifier(activation='logistic', hidden_layer_sizes=100, random_state=1),\t\n",
        "]\n",
        "    \n",
        "\n",
        "best_rand_cls = [\n",
        "    XGBClassifier(booster='dart', gamma=0.2222311111111111, learning_rate=0.3000066666666667, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1000088888888889, n_estimators=36, random_state=42),\n",
        "    SVC(C=1.5555577777777776, kernel='sigmoid', max_iter=400, random_state=1),\n",
        "    LogisticRegression(C=0.4444522222222222, random_state=1),\n",
        "    RandomForestClassifier(max_depth=2, n_estimators=36, random_state=1),\n",
        "    MLPClassifier(activation='logistic',alpha=0.055564444444444444, hidden_layer_sizes=101, random_state=1)\t\t\t\t\t\n",
        "]\n",
        "\n",
        "\n",
        "Tuned_models = [ \n",
        "    LogisticRegression(C=0.75005, penalty='l2', random_state=1),\n",
        "    LogisticRegression(C=0.5, penalty='none', random_state=1),\n",
        "\n",
        "\n",
        "    RandomForestClassifier(n_estimators=125, max_depth = 60, criterion= 'gini', random_state=1),\n",
        "    RandomForestClassifier(n_estimators=125, random_state=1),\n",
        "\t\n",
        "\n",
        "    AdaBoostClassifier(algorithm='SAMME.R', learning_rate=1.125025, n_estimators=98, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42),\n",
        "    \n",
        "    XGBClassifier(booster='gblinear', gamma=0.5, learning_rate=0.01, random_state=42),\n",
        "    XGBClassifier(booster='gbtree',n_estimators=500, learning_rate=000.1, random_state=7)\t\n",
        "\t\n",
        "]\n",
        "\n",
        "\n",
        "esti_model = [\n",
        "    AdaBoostClassifier(algorithm='SAMME.R', learning_rate=1.125025, n_estimators=98, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42),\n",
        "    XGBClassifier(booster='gblinear', gamma=0.5, learning_rate=0.01, random_state=42),\n",
        "    XGBClassifier(booster='gbtree',n_estimators=500, learning_rate=000.1, random_state=7)\t\n",
        "\t\n",
        "]"
      ],
      "metadata": {
        "id": "2QS5v7dvTzJJ"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "    \n",
        "# Feature selection using RFE\n",
        "recursive_feature_list = []\n",
        "def recursive_feature_eng(model, X, Y, n_features):\n",
        "    print(\"-\"*90)\n",
        "    rfe = RFE(model, n_features_to_select=n_features)\n",
        "    rfe_fit = rfe.fit(X,Y)\n",
        "#    print(\"Number of features chosen: %d\" % rfe_fit.n_features_)\n",
        "    recursive_feature_list.append(rfe_fit.get_feature_names_out())\n",
        "    print('Features selected from data are ', rfe_fit.get_feature_names_out())\n",
        "  \n",
        "    return rfe_fit\n",
        "\n",
        "for mod in Tuned_models:\n",
        "  recursive_feature_eng(mod, X, y, 10)\n"
      ],
      "metadata": {
        "id": "H-KjFQCFqqW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recursive_feature_list"
      ],
      "metadata": {
        "id": "MMGk56v0qqSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def chi2Feats(X, y):\n",
        "  chi_selector = SelectKBest(chi2)\n",
        "  X_norm = MinMaxScaler().fit_transform(X)\n",
        "  chifeats = chi_selector.fit(X_norm, y)\n",
        "  return chifeats.get_feature_names_out()\n",
        "\n",
        "\n",
        "def mut_info_cls(X,y, threshold=float):\n",
        "  mi = mutual_info_classif(X=X,y=y,random_state=42, discrete_features=False)      \n",
        "  dfinfo = pd.DataFrame(mi, index=X.columns)\n",
        "  filterlabels = dfinfo[dfinfo[0] >= threshold] \n",
        "  return X[filterlabels.index]\n",
        "\n",
        "\n",
        "mifeats = mut_info_cls(X, y, 0.125)\n",
        "Mut_infolist = list(mifeats.columns)\n",
        "feats_list.append(Mut_infolist)\n",
        "\n",
        "\n",
        "chi2Featslist = chi2Feats(X, y)\n",
        "chi_Selected = X_to_drop.iloc[:,[5, 50, 75, 84, 85, 142, 154, 156, 158,188]]\n",
        "feats_list.append(list(chi_Selected.columns))"
      ],
      "metadata": {
        "id": "0ePG0tEKqqM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ptqcx4D6Bkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdHaLFIP6Bio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLtcSjMk6BeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFpr\n"
      ],
      "metadata": {
        "id": "64IEFqmzJmRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "selectFeaturesSelectFpr=SelectFpr(score_func= f_classif) #Percentile here denotes % features to keep\n",
        "\n",
        "selectFeaturesSelectFpr.fit(X,y)\n",
        "\n",
        "feats_list.append(list(selectFeaturesSelectFpr.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "nrVHAOB3Lmfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqbl-UlEJmMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "SelFromModel_feature_list = []\n",
        "   \n",
        "def SelFromModel(X, y, model, threshold=float):    \n",
        "  select = SelectFromModel(model, threshold=threshold)\n",
        "  select.fit(X, y)\n",
        "  SelFromModel_feature_list.append(select.get_feature_names_out())\n",
        "  print('Features selected from data are ', select.get_feature_names_out())\n",
        "\n",
        "  X_selected = select.transform(X)\n",
        "\n",
        "  return X[select.get_feature_names_out()]\n",
        "  \n",
        "\n",
        "for i in esti_model:\n",
        "  SelFromModel(X, y, i, threshold= 0.045)"
      ],
      "metadata": {
        "id": "aaQ3wO786Bb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dqxv5xFL6BYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import  f_classif\n",
        "\n",
        "#FeaturesFromANOVAlist = []\n",
        "\n",
        "selectFeaturesFromANOVA=SelectPercentile(percentile=10,score_func= f_classif) #Percentile here denotes % features to keep\n",
        "\n",
        "selectFeaturesFromANOVA.fit(X,y)\n",
        "\n",
        "feats_list.append(list(selectFeaturesFromANOVA.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "_H664bhX6BVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BorutaShaplist = []\n"
      ],
      "metadata": {
        "id": "pUt6GpGw6BRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install BorutaShap\n",
        "from BorutaShap import BorutaShap\n",
        "\n",
        "BorutaShaplist = []\n",
        "\n",
        "# If no model is selected default is the Random Forest\n",
        "# If classification is True it is a classification problem\n",
        "Feature_Selectorshap = BorutaShap(importance_measure='shap', classification=True)\n",
        "\n",
        "\n",
        "Feature_Selectorshap.fit(X=X, y=y, n_trials=250, random_state=0)\n",
        "\n",
        "# Returns a subset of the original data with the selected features\n",
        "subsetOne = Feature_Selectorshap.Subset()\n",
        "subsetOne.head()\n",
        "BorutaShaplist.append(subsetOne.columns)"
      ],
      "metadata": {
        "id": "5t9NYjIl-wbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BorutaShaplist.append(subsetOne.columns)"
      ],
      "metadata": {
        "id": "8G6p-8VDA_Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_Selectorsample = BorutaShap(importance_measure='shap', classification=True)\n",
        "\n",
        "Feature_Selectorsample.fit(X=X, y=y, n_trials=100, random_state=0, sample=True)\n",
        "\n",
        "subsetTwo = Feature_Selectorsample.Subset()\n",
        "subsetTwo.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "B63txr4v-rVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BorutaShaplist.append(subsetTwo.columns)"
      ],
      "metadata": {
        "id": "9SA8G8qhBGGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no model selected default is Random Forest, if classification is False it is a Regression problem\n",
        "Feature_Selectorgini = BorutaShap(importance_measure='gini',classification=True)\n",
        "\n",
        "Feature_Selectorgini.fit(X=X, y=y, n_trials=100, random_state=0)\n",
        "\n",
        "subsetTres = Feature_Selectorgini.Subset()\n",
        "subsetTres.head()\n"
      ],
      "metadata": {
        "id": "TyAJEf0b-rSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BorutaShaplist.append(subsetTres.columns)"
      ],
      "metadata": {
        "id": "YZIyeBUEBL7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no model selected default is Random Forest, if classification is False it is a Regression problem\n",
        "Feature_Selectorginisample = BorutaShap(importance_measure='gini',classification=True)\n",
        "\n",
        "Feature_Selectorginisample.fit(X=X, y=y, n_trials=100, sample=True, random_state=0)\n",
        "\n",
        "subsetFour = Feature_Selectorginisample.Subset()\n",
        "subsetFour.head()\n",
        "BorutaShaplist.append(subsetFour.columns)"
      ],
      "metadata": {
        "id": "vOcoAslm-rOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BorutaShaplist.append(subsetFour.columns)"
      ],
      "metadata": {
        "id": "FPWDt0no-rLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmmuhQVR-rH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "shap_models = [\n",
        "    \n",
        "\n",
        "    RandomForestClassifier(n_estimators=125, max_depth = 60, criterion= 'gini', random_state=1).fit(X_train, y_train),\n",
        "    RandomForestClassifier(n_estimators=125, random_state=1).fit(X_train, y_train)]\n",
        "\n",
        "\n",
        "import shap\n",
        "# =============================================================================\n",
        "# Shapley Values for Feature Importance\n",
        "# =============================================================================\n",
        "# Fit relevant explainer\n",
        "def extract_shap(model, X, threshold=float):\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values = explainer.shap_values(X)\n",
        "  # View shap values\n",
        "  shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "  importance_df = pd.DataFrame([X_train.columns.tolist(), shap_sum.tolist()]).T\n",
        "  importance_df.columns = ['column_name', 'shap_importance']\n",
        "  importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
        "  shapselected = importance_df[importance_df['shap_importance'] != threshold]\n",
        "  print(shapselected)    \n",
        "\n",
        "\n",
        "\n",
        "for i in shap_models:\n",
        "  extract_shap(i, X,threshold= 0)\n",
        "  '''"
      ],
      "metadata": {
        "id": "LPDDhp7j6BN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "recursive_feature_list, SelFromModel_feature_list\n"
      ],
      "metadata": {
        "id": "0_0GlIs6cdxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyGQ4IxorwHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_selectors = ['chi2','mutual_info_classif','SelectFromModel','BorutaShapSelected','VarianceThreshold', 'RecursiveElimination']\n",
        "\n",
        "BestClsresults = {'Classifier': [],\"Accuracy Score\": [], 'Datasetfrom':[]}\n",
        "\n",
        "\n",
        "names = [\n",
        "    \"XGB\",\n",
        "    \"ADABoost\"\n",
        "    \"SVC\",\n",
        "    \"LogReg\",    \n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\"]\n",
        "\n",
        "bestcls = [\n",
        "    XGBClassifier(booster='gblinear', gamma=0.5, learning_rate=0.01, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42)\t,\n",
        "    SVC(kernel='sigmoid', max_iter=500, random_state=1),\n",
        "    LogisticRegression(C=0.5, penalty='none', random_state=1),\n",
        "    RandomForestClassifier(n_estimators=125, random_state=1),\t\n",
        "    MLPClassifier(activation='logistic', hidden_layer_sizes=100, random_state=1)\n",
        "    ]\n",
        "\n",
        "concatfeats = list(unique_values)\n",
        "for ds_cnt, ds in zip(feature_selectors,feats_list):\n",
        "  X, y = X_to_drop[ds], y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.20)\n",
        "\n",
        "  for clf, name in zip(bestcls, names):\n",
        "    clf.fit(X_train, y_train)\n",
        "    pred = clf.predict(X_test)\n",
        "    score = accuracy_score(y_test, pred) \n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    cr = classification_report(y_test, pred)\n",
        "\n",
        "    BestClsresults['Classifier'].append(name)\n",
        "    BestClsresults['Accuracy Score'].append(score)\n",
        "    BestClsresults['Datasetfrom'].append(ds_cnt)\n",
        "    \n",
        "\n",
        "    print(\"-\"*90)\n",
        "    print(\"Test Score: {} With Classifier: {}\".format(score, clf))\n",
        "    print(\"-\"*90)\n",
        "    print(\"printing classification report to console along with dataset and dataset number: \")\n",
        "    print(\"{} : {}\".format(ds, ds_cnt))\n",
        "\n",
        "    print(\"-\"*90)\n",
        "    print(\"CLASS_REPORT: {}\".format(cr))\n",
        "    print(\"-\"*90) \n",
        "\n",
        "performance_df = pd.DataFrame(BestClsresults)          "
      ],
      "metadata": {
        "id": "jXvRnMYgcduR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df"
      ],
      "metadata": {
        "id": "is7t3sZOcdq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--tUaxGscdof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_selectors = ['chi2','mutual_info_classif','SelectFromModel','BorutaShapSelected','VarianceThreshold', 'RecursiveElimination']\n",
        "\n",
        "BestRandresults = {'Classifier': [],\"Accuracy Score\": [], 'Datasetfrom':[]}\n",
        "\n",
        "\n",
        "names = [\n",
        "    \"XGB\",\n",
        "    \"ADABoost\",\n",
        "    \"SVC\",\n",
        "    \"LogReg\",    \n",
        "    \"Random Forest\",\n",
        "    \"Neural Net\",\n",
        "]\n",
        "\n",
        "bestclsFromRand = [\n",
        "    XGBClassifier(booster='dart', gamma=0.0001, learning_rate=0.0001, random_state=42),\n",
        "    AdaBoostClassifier(algorithm='SAMME.R', learning_rate=1.125025, n_estimators=98, random_state=42)\t,\n",
        "    SVC(C=1.5, kernel='poly', max_iter=987, random_state=1),\n",
        "    LogisticRegression(C=0.75005, penalty='l2', random_state=1),\n",
        "    RandomForestClassifier(n_estimators=125, max_depth = 60, criterion= 'gini', random_state=1),\t\n",
        "    MLPClassifier(activation='logistic', hidden_layer_sizes=125,  alpha=0.07502500000000001, random_state=1),\t\n",
        "]\n",
        "\n",
        "concatfeats = list(unique_values)\n",
        "for ds_cnt, ds in zip(feature_selectors,feats_list):\n",
        "  X, y = X_to_drop[ds], y\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.20)\n",
        "\n",
        "  for clf, name in zip(bestclsFromRand, names):\n",
        "    clf.fit(X_train, y_train)\n",
        "    pred = clf.predict(X_test)\n",
        "    score = accuracy_score(y_test, pred) \n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    cr = classification_report(y_test, pred)\n",
        "\n",
        "    BestRandresults['Classifier'].append(name)\n",
        "    BestRandresults['Accuracy Score'].append(score)\n",
        "    BestRandresults['Datasetfrom'].append(ds_cnt)\n",
        "    \n",
        "\n",
        "    print(\"-\"*90)\n",
        "    print(\"Test Score: {} With Classifier: {}\".format(score, clf))\n",
        "    print(\"-\"*90)\n",
        "    print(\"printing classification report to console along with dataset and dataset number: \")\n",
        "    print(\"{} : {}\".format(ds, ds_cnt))\n",
        "\n",
        "    print(\"-\"*90)\n",
        "    print(\"CLASS_REPORT: {}\".format(cr))\n",
        "    print(\"-\"*90) \n",
        "\n",
        "Randperformance_df = pd.DataFrame(BestRandresults)          "
      ],
      "metadata": {
        "id": "FFRawRO5cdlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Randperformance_df"
      ],
      "metadata": {
        "id": "6uVbyDrncdhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HurmctSuglCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHxeP6QzglBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kg-SGwMYgk9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOHYpmk3gk5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-IyBmqUcdfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPmCjVdKcdav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Izx94QFqcdXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = {'Classifer':[], 'test_acc': [], 'test_prec_macro':[], 'test_rec_micro':[]}\n",
        "svcclf = SVC(kernel='sigmoid', max_iter=500, random_state=1)\n",
        "logregclf = LogisticRegression(C=0.5, penalty='none', random_state=1)\n",
        "rf_clf = RandomForestClassifier(n_estimators=125, random_state=1)\n",
        "mlpclf = MLPClassifier(activation='logistic', hidden_layer_sizes=100, random_state=1)\n",
        "voting_clf = VotingClassifier(estimators=[('lr', logregclf), ('rf', rf_clf), ('svc', svcclf), ('mlp', mlpclf)], voting='hard')\n",
        "scoring = {'acc': 'accuracy',\n",
        "           'prec_macro': 'precision_macro',\n",
        "           'rec_micro': 'recall_macro'}\n",
        "\n",
        "  \n",
        "for clf in (logregclf, rf_clf, svcclf, mlpclf, voting_clf):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_to_drop[univals], y, random_state=11, test_size=.20)\n",
        "\n",
        "  scores = cross_validate(clf, X_train, y_train, scoring=scoring,\n",
        "                         cv=10, return_train_score=True)\n",
        "  scoreKeys = pd.DataFrame(scores)\n",
        "  docs['Classifer'].append(clf.__class__.__name__)\n",
        "  docs['test_acc'].append(scoreKeys.test_acc)\n",
        "  docs['test_acc'].append(scoreKeys.test_acc)\n",
        "\n",
        "  print(\"-\"*90)\n",
        "  print(f\"Cross Validaion Metrics for {clf.__class__.__name__}:\")\n",
        "  print(scoreKeys[['test_acc','test_prec_macro','test_rec_micro']].mean())\n",
        "  print(\"-\"*90)\n",
        "  "
      ],
      "metadata": {
        "id": "PNp9ghr0qAnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVlc3VtbHbZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rand_docs = {'Classifer':[], 'test_acc': [], 'test_prec_macro':[], 'test_rec_micro':[]}\n",
        "\n",
        "XGB = XGBClassifier(booster='gblinear', gamma=0.5, learning_rate=0.01, random_state=42)\n",
        "Ada = AdaBoostClassifier(algorithm='SAMME', learning_rate=1.5, n_estimators=75, random_state=42)\t\n",
        "Svc = SVC(kernel='sigmoid', max_iter=500, random_state=1)\n",
        "Logreg = LogisticRegression(C=0.5, penalty='none', random_state=1)\n",
        "Rf = RandomForestClassifier(n_estimators=125, random_state=1)\n",
        "Mlp = MLPClassifier(activation='logistic', hidden_layer_sizes=100, random_state=1)\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('XGB', XGB), ('Ada', Ada), ('svc', Svc), ('Logreg', Logreg), ('Rf', Rf), ('Mlp', Mlp)], voting='hard')\n",
        "scoring = {'acc': 'accuracy',\n",
        "           'prec_macro': 'precision_macro',\n",
        "           'rec_micro': 'recall_macro'}\n",
        "\n",
        "  \n",
        "for clf in (XGB, Ada, Svc, Logreg, Rf, Mlp, voting_clf):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_to_drop[univals], y, random_state=11, test_size=.20)\n",
        "\n",
        "  rand_scores = cross_validate(clf, X_train, y_train, scoring=scoring,\n",
        "                         cv=10, return_train_score=True)\n",
        "  rand_scoreKeys = pd.DataFrame(rand_scores)\n",
        "  rand_docs['Classifer'].append(clf.__class__.__name__)\n",
        "  rand_docs['test_acc'].append(scoreKeys.test_acc)\n",
        "  rand_docs['test_acc'].append(scoreKeys.test_acc)\n",
        "\n",
        "  print(\"-\"*90)\n",
        "  print(f\"Cross Validaion Metrics for {clf.__class__.__name__}:\")\n",
        "  print(rand_scoreKeys[['test_acc','test_prec_macro','test_rec_micro']].mean())\n",
        "  print(\"-\"*90)\n",
        "  "
      ],
      "metadata": {
        "id": "Vx87vK2nkkn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H91Ab_a7HNUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tkwU4YeHNXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UEsCZ2Y9HNaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCxMyv0LHNdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        CatBoostClassifier(random_state=42),\n",
        "\n",
        "    {'depth': [4,5,7],'learning_rate' : [0.01,0.03,0.04],'iterations' : [50,60,70]},\n",
        "\n",
        "feats_list.append(['abQ_IGHG1',\n",
        " 'pQ1_SERPINC1',\n",
        " 'pQ2_KLKB1',\n",
        " 'pQ2_SERPINF2_a',\n",
        " 'pQ2_SERPINF2_b',\n",
        " 'pQ5_SERPINF2',\n",
        " 'pQ6_SERPINA10',\n",
        " 'pQ6_SERPINA5',\n",
        " 'pQ7_ATRN'])\n",
        "\n",
        "feats_list.append(['abQ_IGJ',\n",
        " 'pQ1_APOC1',\n",
        " 'pQ2_APOE',\n",
        " 'pQ2_F2_a',\n",
        " 'pQ3_CPB2',\n",
        " 'pQ5_A2M',\n",
        " 'pQ5_CFB',\n",
        " 'pQ5_FABP1',\n",
        " 'pQ6_C1R',\n",
        " 'pQ6_LGALS3BP',\n",
        " 'pQ6_SERPINA10',\n",
        " 'pQ6_SERPINA5',\n",
        " 'pQ7_C1QA',\n",
        " 'pQ7_GSTA1',\n",
        " 'pQ8_CPN1'])\n",
        "\n",
        "feats_list.append(['abQ_LV302',\n",
        " 'pQ1_IGKC',\n",
        " 'pQ1_SERPINC1',\n",
        " 'pQ2_ITIH1',\n",
        " 'pQ2_KLKB1',\n",
        " 'pQ3_PROC_a',\n",
        " 'pQ3_PROS1_a',\n",
        " 'pQ3_VWF',\n",
        " 'pQ5_FABP1',\n",
        " 'pQ6_C1R',\n",
        " 'pQ6_SERPINA5',\n",
        " 'pQ7_ATRN',\n",
        " 'pQ7_CST3',\n",
        " 'pQ7_GSTA1',\n",
        " 'pQ7_MPO',\n",
        " 'pQ8_PAR2'])\n",
        "\n",
        "feats_list.append(['pQ6_SERPINA10', 'pQ2_SERPINF2_a', 'pQ7_ATRN', 'pQ8_PAR2', 'pQ7_CPB2','pQ7_PRG4'])\n",
        "\n",
        "feats_list.append(['abQ_IGHA1_2',\n",
        " 'abQ_IGHA2',\n",
        " 'pQ2_HBA1',\n",
        " 'pQ2_HBB',\n",
        " 'pQ3_CA1',\n",
        " 'pQ3_CRP_a',\n",
        " 'pQ3_CRP_b',\n",
        " 'pQ3_MB',\n",
        " 'pQ4_FABP1',\n",
        " 'pQ5_FABP1',\n",
        " 'pQ5_SAA1_A2',\n",
        " 'pQ7_CFD',\n",
        " 'pQ7_CXCL7',\n",
        " 'pQ7_GSTA1',\n",
        " 'pQ7_PLF4',\n",
        " 'pQ7_THBD',\n",
        " 'pQ8_PLAT',\n",
        " 'cn_ly30'])\n",
        "\n",
        "feats_list.append(['pQ2_APOE',\n",
        " 'pQ3_PROC_b',\n",
        " 'pQ5_SERPINF2',\n",
        " 'pQ6_C8B',\n",
        " 'pQ6_SERPINA10',\n",
        " 'pQ6_SERPINA5',\n",
        " 'pQ8_PAR2'])\n",
        "unique_values = set()\n",
        "for sublist in feats_list:\n",
        "    for value in sublist:\n",
        "        unique_values.add(value)\n",
        "\n",
        "univals = list(unique_values)\n",
        "\n",
        "feature_selectors = ['chi2','mutual_info_classif','SelectFromModel','BorutaShapSelected','VarianceThreshold', 'RecursiveElimination']"
      ],
      "metadata": {
        "id": "8VSA7RwKHNgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kehz28J-HNjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XT66f-iCHNmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwDjEdVGHNq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6ZcPcI4HNtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMHpJPvyHNvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GRfFBH_HNzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgbV__5qHN3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pyyg9H0_HN55"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}