{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8909d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced deep-learning best practices: Introduction to the functional API\n",
    "\n",
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Preparing higher-resolution data generator for the jena datset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras import applications, layers, Input\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from pylab import mpl, plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fedf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reweighting a probality distribution to a different temprature \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# orginal distribution is a 1D np array of prebability values that must sum to 1.\n",
    "# temperature is a factor quantifying the entropy is a factor quantifying the entropy of the output distribution.\n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution)/ temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    \n",
    "    return distribution / np.sum(distribution)\n",
    "\n",
    "# Returns a reweighted version of the orginal distrbution. The sum of the distribution may no longer be 1,\n",
    "    # so divide it by its sum ot ontrain the new distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6925c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "# Implementing character-level LSTM text generation\n",
    "\n",
    "path = tf.keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "text = open(path).read().lower()\n",
    "\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14596804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seqiences: 200281\n",
      "Unique characters: 59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing sequences of charecters \n",
    "\n",
    "maxlen = 60 \n",
    "\n",
    "step = 3 \n",
    "\n",
    "sentences = []\n",
    "\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('Number of seqiences:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "char_indeces = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print(\"Vectorization...\")\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i , sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indeces[char]] =1\n",
    "    y[i, char_indeces[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f24829b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building The NetWork:\n",
    "This network is a single LSTM layer followed by a Dense classifier and softmax over all possible charecters.\n",
    "Note: 1D convnets also have proven extremly successful at this task in rencent times.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "char_preModel = tensorflow.keras.models.Sequential()\n",
    "\n",
    "char_preModel.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "char_preModel.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# Used categorical_crossentropy to deal with one-hot encoded targets.\n",
    "\n",
    "# Model compilation configuration \n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "char_preModel.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02a97a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample the next character given the model's predictions \n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "179a5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFinally, the following loop repeatedly trains and generates text.\\nYou begin generating text using a range of different temeparatures after every epoch. \\nThis allows you to see how the genarated text evolves as the model begins to convege,\\nas well as the impact of temperature in the sampling strategy.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, the following loop repeatedly trains and generates text.\n",
    "You begin generating text using a range of different temeparatures after every epoch. \n",
    "This allows you to see how the genarated text evolves as the model begins to convege,\n",
    "as well as the impact of temperature in the sampling strategy.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e93a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 92s 458us/sample - loss: 1.6346\n",
      "--- Generating with seed: \"ain, \"stronger, more evil, and more profound; also more\n",
      "beau\"\n",
      "epoch 2\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 454us/sample - loss: 1.5443\n",
      "--- Generating with seed: \"hand-dilation,\n",
      "this incense-fuming exaltation? is ours this \"\n",
      "epoch 3\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 92s 457us/sample - loss: 1.4985\n",
      "--- Generating with seed: \" of\n",
      "independence.\n",
      "\n",
      "42. a new order of philosophers is appear\"\n",
      "epoch 4\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 456us/sample - loss: 1.4684\n",
      "--- Generating with seed: \"phlegm in the former and\n",
      "with hard skulls in the latter--not\"\n",
      "epoch 5\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 455us/sample - loss: 1.4479\n",
      "--- Generating with seed: \"endowed with\n",
      "intellectual goods and privileges, are equal to\"\n",
      "epoch 6\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 456us/sample - loss: 1.4315\n",
      "--- Generating with seed: \"hut my eyes to schopenhauer's blind will\n",
      "towards ethic, at a\"\n",
      "epoch 7\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 455us/sample - loss: 1.4164\n",
      "--- Generating with seed: \"e more searchingly do men look to the\n",
      "elimination of evil it\"\n",
      "epoch 8\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 91s 456us/sample - loss: 1.4040\n",
      "--- Generating with seed: \"e spirits\"--as glib-tongued and scribe-fingered slaves of\n",
      "th\"\n",
      "epoch 9\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 92s 458us/sample - loss: 1.3960\n",
      "--- Generating with seed: \"ce towards humanity. on the contrary, in\n",
      "the so-called cultu\"\n",
      "epoch 10\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 467us/sample - loss: 1.3866\n",
      "--- Generating with seed: \"ure; through this \"belief\" of\n",
      "theirs, they exert themselves \"\n",
      "epoch 11\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 465us/sample - loss: 1.3797\n",
      "--- Generating with seed: \"ses plaies,\n",
      "according to balzac--i would venture to protest \"\n",
      "epoch 12\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 466us/sample - loss: 1.3730\n",
      "--- Generating with seed: \"pect, nor better than we\": a fine instance of secret motive,\"\n",
      "epoch 13\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 466us/sample - loss: 1.3671\n",
      "--- Generating with seed: \"nendurable, is the\n",
      "appearance of an absolute ruler for these\"\n",
      "epoch 14\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 94s 471us/sample - loss: 1.3626\n",
      "--- Generating with seed: \"nsciously determine to evolve to a new civilization\n",
      "where fo\"\n",
      "epoch 15\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 94s 468us/sample - loss: 1.3570\n",
      "--- Generating with seed: \"\n",
      "his possession, when she no longer deceives herself about h\"\n",
      "epoch 16\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 96s 479us/sample - loss: 1.3534\n",
      "--- Generating with seed: \"ially in the relationship to the\n",
      "olympian gods, it becomes p\"\n",
      "epoch 17\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 94s 469us/sample - loss: 1.3486\n",
      "--- Generating with seed: \"nothing....\n",
      "\n",
      "245. the \"good old\" time is past, it sang itsel\"\n",
      "epoch 18\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 94s 467us/sample - loss: 1.3436\n",
      "--- Generating with seed: \"e itself among the virtues,\n",
      "under the name of \"justice.\" a t\"\n",
      "epoch 19\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 465us/sample - loss: 1.3422\n",
      "--- Generating with seed: \"stood on the\n",
      "defensive against all synthetic tasks and capab\"\n",
      "epoch 20\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 464us/sample - loss: 1.3358\n",
      "--- Generating with seed: \" be\n",
      "believed. how little it would be worth, then!\n",
      "\n",
      "\n",
      "121\n",
      "\n",
      "=da\"\n",
      "epoch 21\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 464us/sample - loss: 1.3341\n",
      "--- Generating with seed: \"mploy theological terms, an enemy and\n",
      "challenger of god; and\"\n",
      "epoch 22\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 464us/sample - loss: 1.3337\n",
      "--- Generating with seed: \"n,\n",
      "sinfulness, unworthiness: he sees in them merely the flit\"\n",
      "epoch 23\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 100s 497us/sample - loss: 1.3295\n",
      "--- Generating with seed: \"d the flash lights of a\n",
      "still unestablished, still precariou\"\n",
      "epoch 24\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 96s 480us/sample - loss: 1.3672\n",
      "--- Generating with seed: \"is\n",
      "not sufficiently sensible to the higher, finer impulses w\"\n",
      "epoch 25\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 96s 481us/sample - loss: 1.3275\n",
      "--- Generating with seed: \" reports of travelers agree). in the\n",
      "dream this atavistic re\"\n",
      "epoch 26\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 94s 470us/sample - loss: 1.3254\n",
      "--- Generating with seed: \"vidence--perhaps\n",
      "among men who enjoyed even stronger and mor\"\n",
      "epoch 27\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 466us/sample - loss: 1.3217\n",
      "--- Generating with seed: \"n general a surplus of\n",
      "protection and care, immediately tend\"\n",
      "epoch 28\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 465us/sample - loss: 1.3252\n",
      "--- Generating with seed: \"o took\n",
      "things seriously, and has been taken seriously from t\"\n",
      "epoch 29\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 463us/sample - loss: 1.3146\n",
      "--- Generating with seed: \"t\n",
      "is involuntarily believed that the religious tinted sectio\"\n",
      "epoch 30\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 467us/sample - loss: 1.3136\n",
      "--- Generating with seed: \"religious worship.=--let us transport ourselves back to the\n",
      "\"\n",
      "epoch 31\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 466us/sample - loss: 1.4217\n",
      "--- Generating with seed: \"n who are now inhuman must serve us as\n",
      "surviving specimens o\"\n",
      "epoch 32\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 93s 462us/sample - loss: 1.3286\n",
      "--- Generating with seed: \"han\n",
      "this only occasionally advantageous quality of psycholog\"\n",
      "epoch 33\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 99s 496us/sample - loss: 1.3156\n",
      "--- Generating with seed: \"of heredity, just as little is \"being-conscious\" opposed\n",
      "to \"\n",
      "epoch 34\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 98s 489us/sample - loss: 1.3251\n",
      "--- Generating with seed: \"ary?\n",
      "     my honey--who hath sipped its fragrancy?\n",
      "\n",
      "        \"\n",
      "epoch 35\n",
      "Train on 200281 samples\n",
      " 56704/200281 [=======>......................] - ETA: 1:11 - loss: 1.2955"
     ]
    }
   ],
   "source": [
    "# Text-generation loop\n",
    "\n",
    "import random \n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch',epoch)\n",
    "    char_preModel.fit(x, y, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print('------ temperature:' temperature)\n",
    "    sys.stdout.write(generated_text)\n",
    "    \n",
    "    \n",
    "for i in range(400):\n",
    "    sampled = np.zeors((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(generated_text):\n",
    "        sampled[0, t, char_indices[char]] = 1 \n",
    "        \n",
    "    preds = char_preModel.predict(sampled, verbore=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = chars[next_index]\n",
    "    \n",
    "    generated_text += next_char\n",
    "    generated_text = generated_text[1:]\n",
    "    \n",
    "    sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007fe7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
