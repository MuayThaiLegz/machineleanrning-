{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae62d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced deep-learning best practices: Introduction to the functional API\n",
    "\n",
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Preparing higher-resolution data generator for the jena datset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras import applications, layers, Input\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from pylab import mpl, plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a86e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reweighting a probality distribution to a different temprature \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# orginal distribution is a 1D np array of prebability values that must sum to 1.\n",
    "# temperature is a factor quantifying the entropy is a factor quantifying the entropy of the output distribution.\n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution)/ temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    \n",
    "    return distribution / np.sum(distribution)\n",
    "\n",
    "# Returns a reweighted version of the orginal distrbution. The sum of the distribution may no longer be 1,\n",
    "    # so divide it by its sum ot ontrain the new distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3df666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "# Implementing character-level LSTM text generation\n",
    "\n",
    "path = tf.keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "text = open(path).read().lower()\n",
    "\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a31e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seqiences: 200281\n",
      "Unique characters: 59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing sequences of charecters \n",
    "\n",
    "maxlen = 60 \n",
    "\n",
    "step = 3 \n",
    "\n",
    "sentences = []\n",
    "\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('Number of seqiences:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "char_indeces = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print(\"Vectorization...\")\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i , sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indeces[char]] =1\n",
    "    y[i, char_indeces[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "886ba27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building The NetWork:\n",
    "This network is a single LSTM layer followed by a Dense classifier and softmax over all possible charecters.\n",
    "Note: 1D convnets also have proven extremly successful at this task in rencent times.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "char_preModel = tensorflow.keras.models.Sequential()\n",
    "\n",
    "char_preModel.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "char_preModel.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# Used categorical_crossentropy to deal with one-hot encoded targets.\n",
    "\n",
    "# Model compilation configuration \n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "char_preModel.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f438ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample the next character given the model's predictions \n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11e6dc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFinally, the following loop repeatedly trains and generates text.\\nYou begin generating text using a range of different temeparatures after every epoch. \\nThis allows you to see how the genarated text evolves as the model begins to convege,\\nas well as the impact of temperature in the sampling strategy.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, the following loop repeatedly trains and generates text.\n",
    "You begin generating text using a range of different temeparatures after every epoch. \n",
    "This allows you to see how the genarated text evolves as the model begins to convege,\n",
    "as well as the impact of temperature in the sampling strategy.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-generation loop\n",
    "\n",
    "import random \n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch',epoch)\n",
    "    char_preModel.fit(x, y, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55473134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train on 200281 samples\n",
      " 28288/200281 [===>..........................] - ETA: 1:24 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/388030325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mchar_preModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Text-generation loop\n",
    "\n",
    "import random \n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch',epoch)\n",
    "    char_preModel.fit(x, y, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    \n",
    "    \n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "        \n",
    "        \n",
    "    for i in range(400):\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indeces[char]] = 1 \n",
    "        \n",
    "        preds = char_preModel.predict(sampled, verbose=0)[:0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = chars[next_index]\n",
    "    \n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "    \n",
    "        sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be15065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e215044",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/3842326947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m deepMindModel = inception_v3.InceptionV3(weights='imagenet',\n\u001b[1;32m---> 11\u001b[1;33m                                         include_top=False)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_applications\\inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[0;32m    181\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \"\"\"\n\u001b[0;32m    644\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;34m'keras_version'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m     \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keras_version'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# DeepDream:\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "#from tensorflow.keras import backed as K\n",
    "\n",
    "#K.set_learning_phase(0)\n",
    "\n",
    "deepMindModel = inception_v3.InceptionV3(weights='imagenet',\n",
    "                                        include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb58218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the DeepDream configuration \n",
    "\n",
    "layer_contributions = {   # Dictionary mapping layers names to a coefficient quantifying how much the layers ativation\n",
    "    'mixed2': 0.2,        # cantributes to the loss you'll seek to maxize.\n",
    "    'mixed3': 3.,         # NOTE The layer names are hardcored in hte built-in inception V3 application.\n",
    "    'mixed4': 2.,         # List all layer names using model.summary()\n",
    "    'mized5': 1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ece5ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2387320720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#layer_dict = dict([(layer_contributions.name, layer) for layer in model.layers])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_contributions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now define a tensor that contains the loss:\n",
    "The weighted sum of the L2 norm of the activation of the layers in listing above.\n",
    "\n",
    "\n",
    "# Defining the loss to be maximized \n",
    "\n",
    "'''\n",
    "\n",
    "#layer_dict = dict([(layer_contributions.name, layer) for layer in model.layers])\n",
    "\n",
    "loss = K.variable(0.)\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2, :])) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03d000c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e8828bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 W 2 R 3g'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '1 w 2 r 3g'\n",
    "\n",
    "\n",
    "def solve(s):\n",
    "    s = s.title()[:-1]\n",
    "    return s +'g'\n",
    "\n",
    "solve(s)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62439d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "17cf9622",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deepMindModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1035838325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Gradient-ascent process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepMindModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deepMindModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gradient-ascent process\n",
    "\n",
    "dream = deepMindModel.input\n",
    "\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "grads /= K.maximum(k.mean(k.abs(grads)), le-7)\n",
    "\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_andgrads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    \n",
    "    return loss_value, grad_values\n",
    "\n",
    "\n",
    "def gradient_ascent(x, inrations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_andgrads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        \n",
    "        x += step * grad_values\n",
    "        \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b88d1fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1273831160.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0moriginal_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Running gradient ascent over different successive scales\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "step = 0.1 \n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 20\n",
    "\n",
    "max_loss = 10\n",
    "\n",
    "base_image_path = '....'\n",
    "\n",
    "\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "original_shape = img.shape[1:3]\n",
    "\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i))\n",
    "                  for dim in orginal_shape])\n",
    "    successive_shapes.append(shape)\n",
    "    \n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "orginal_img = np.copy(img)\n",
    "\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    \n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                         iterations=interations,\n",
    "                         step=step,\n",
    "                         max_loss=max_loss)\n",
    "    \n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(orginal_img, shape)\n",
    "    lost_details = same_size_original - upscaled_shrunk_original_img\n",
    "    \n",
    "    img += lost_details\n",
    "    \n",
    "    shrunk_original_img = resize_img(original_shape, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "    \n",
    "saave_img(img, fname='final_dream.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fdb2b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxlliary functions \n",
    "\n",
    "import scipy\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def resize_img(img, size):\n",
    "    \n",
    "    img = np.copy(img)\n",
    "    \n",
    "    factors = (1,\n",
    "              float(size[0]) / img.shape[1],\n",
    "              float(size[1]) / img.shape[2],\n",
    "              1)\n",
    "    \n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "    \n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "        \n",
    "        x /= 2.\n",
    "        x += 0.5 \n",
    "        x *= 255.\n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58f37288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: Because the original INception V3 network was trained to recognize concepts in images of size 299 x 299,\\nand given that the orecess inclves scaling the images that aare somewhere between 300 x 300 and 400 x 400.\\nRegarless, you can run the same code on images of any size and ratio\\n\\n\\n# Neural style transfer \\n\\nloss = distance(style(reference_image) - style(generated_image)) + distance(content(orginal_image) - content(generated_image))\\n\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE: Because the original INception V3 network was trained to recognize concepts in images of size 299 x 299,\n",
    "and given that the orecess inclves scaling the images that aare somewhere between 300 x 300 and 400 x 400.\n",
    "Regarless, you can run the same code on images of any size and ratio\n",
    "\n",
    "\n",
    "# Neural style transfer \n",
    "\n",
    "loss = distance(style(reference_image) - style(generated_image)) + distance(content(orginal_image) - content(generated_image))\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d190f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b221a3be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'img/portrait.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2732093923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mstyle_referenve_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'img/transfer_style_reference.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mimg_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img/portrait.jpg'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural style transfer in Keras:\n",
    "\n",
    "\n",
    "Defining the paths to the style-reference iamge and the target image.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "target_image_path  = 'img/portrait.jpg'\n",
    "\n",
    "style_referenve_image_path = 'img/transfer_style_reference.jpg'\n",
    "\n",
    "width, height = load_img(target_image_path).size\n",
    "\n",
    "img_height = 400\n",
    "\n",
    "img_width = int(width * img_height / height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ccffb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxillary fucntions \n",
    "\n",
    "from tensorflow.keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "13737fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    \n",
    "    img = img_to_array(img)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    img - vgg19.preprocess_input(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def deprecess_image(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] +=123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "571cffe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/763632217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtarget_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mstyle_reference_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle_referenve_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/488660113.py\u001b[0m in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_height' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading the pretraing VGG19 network fand applying it ti the three images \n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "target_image = K.constant(preprocess_image(target_image_path))\n",
    "\n",
    "style_reference_image = K.constant(preprocess_image(style_referenve_image_path))\n",
    "\n",
    "combination_image = K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "input_tensor = K.concatenate([target_image,\n",
    "                             style_reference_image,\n",
    "                             combination_image], axis=0)\n",
    "\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                   weights='imagenet',\n",
    "                   include_top=False)\n",
    "\n",
    "print('Model loaded.')\n",
    "\n",
    "def contect_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    \n",
    "    channels = 3\n",
    "    \n",
    "    size = img_height * img_width\n",
    "    \n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1c0e651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total variation loss \n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = K.square(x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n",
    "    \n",
    "    b = K.square(x[:, :img_height - 1, :img_width -1, :] - x[:, :img_height - 1, 1:, :])\n",
    "    \n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2db3dce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/4026489573.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Definig the final loss that you'll minize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout_puts_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcontent_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'block5_conv2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Definig the final loss that you'll minize \n",
    "\n",
    "out_puts_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "content_layer = 'block5_conv2'\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "\n",
    "total_variation_weight = 1e-4\n",
    "\n",
    "style_weight = 1.\n",
    "\n",
    "content_weight = 0.025\n",
    "\n",
    "loss = K.variable(0.)\n",
    "\n",
    "layer_features = outputs_dict[content_layer]\n",
    "\n",
    "target_image_features = layer_features[0, :, :, :]\n",
    "\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss += content_weight * content_loss(targer_image_features,\n",
    "                                     combination_features)\n",
    "\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[content_layer]\n",
    "    style_reference_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    \n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6b02b90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combination_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1314455505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrads\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombination_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combination_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up the gradient-descent process \n",
    "\n",
    "loss = K.variable(0.)\n",
    "\n",
    "grads  = K.gradients(loss, combination_image)[0]\n",
    "\n",
    "\n",
    "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
    "\n",
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "    \n",
    "        return grad_values\n",
    "    \n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "190d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "#from scipy.misc import imsave\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style-transfer loop \n",
    "\n",
    "result_prefix = 'my_result'\n",
    "\n",
    "x = preprocess_image(target_image_path)\n",
    "\n",
    "x = x.flatten()\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    x, min_val, info = fmin_1_bfgs_b(evaluator.grads,\n",
    "                                    maxfun=20)\n",
    "    \n",
    "    print('Current loss value:', min_val)\n",
    "    img = x.copy().resahape((img_height, img_width, 3))\n",
    "    \n",
    "    img = deprocess_image(img)\n",
    "    \n",
    "    fname = result_prefix + '_at_iteratio_%d.png' % i\n",
    "    \n",
    "    imsave(fname, img)\n",
    "    \n",
    "    print('Image saved as'. fname)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational autoencoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26086b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/3572712141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_variencee\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_log_variance\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreconstructed_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_variencee = encoder(input_img) # encodes the input into a mean and variance parameter \n",
    "\n",
    "z = z_mean + exp(z_log_variance) * epsilon # Draws a latent point using a small random epsilon \n",
    "\n",
    "reconstructed_img = decoder(z) \n",
    "\n",
    "model = Model(input_img, reconstructed_img) # Instantiates the autoencoder model,\n",
    "                                            # which maps an input image ot its reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db07488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE encoder network \n",
    "\n",
    "import tensorflow.keras \n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "img_shape = (28, 28, 1)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "latent_dim = 2 \n",
    "\n",
    "input_img = keras.Input(shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0dd900be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(32, 3,\n",
    "                 padding='same', activation='relu')(input_img)\n",
    "\n",
    "x = layers.Conv2D(64, 3,\n",
    "                 padding='same', activation='relu', strides=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3,\n",
    "                 padding='same', activation='relu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3,\n",
    "                 padding='same', activation='relu')(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "\n",
    "z_log_var = layers.Dense(latent_dim)(x)\n",
    "\n",
    "# latent-space_sampling function\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args \n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                             mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2e7ba038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE decoder network, mapping latent spce points to images\n",
    "\n",
    "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
    "                activation='relu')(decoder_input)\n",
    "\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(32, 3,\n",
    "                          padding='same',\n",
    "                          activation='relu',\n",
    "                          strides=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(1, 3, \n",
    "                 padding='same',\n",
    "                 activation='sigmoid')(x)\n",
    "\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "z_decoded = decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9eedfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer used to compute the VAE loss\n",
    "\n",
    "class CustomVatiationalLayer(tensorflow.keras.layers.Layer):\n",
    "    \n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        \n",
    "        x = K.flatten(x)\n",
    "        \n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        \n",
    "        xent_loss = tensorflow.keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        \n",
    "        kl_loss = -5e-4 * K.mean(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        \n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        \n",
    "        z_decoded = inputs[1]\n",
    "        \n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        \n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "y = CustomVatiationalLayer()([input_img, z_decoded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "66ab9592",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'op'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1443462200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m    163\u001b[0m       \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m       \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m       \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m  \u001b[1;31m# The Op that created this Tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m       \u001b[1;31m# Recursively set `_keras_history`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'op'"
     ]
    }
   ],
   "source": [
    "# Training the VAE\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "vae = Model(input_img, y)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "\n",
    "vae.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "adbdf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ccb25314",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2381381014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m vae.fit(x=x_train, y=None,\n\u001b[0m\u001b[0;32m      8\u001b[0m        \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float') / 255\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "\n",
    "vae.fit(x=x_train, y=None,\n",
    "       shuffle=True,\n",
    "       epochs=10,\n",
    "       batch_size=batch_size,\n",
    "       validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728eda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ef8f1bc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'sorm' from 'scipy.stats' (C:\\Users\\JBarr\\anaconda3\\envs\\dev\\lib\\site-packages\\scipy\\stats\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2356837631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'sorm' from 'scipy.stats' (C:\\Users\\JBarr\\anaconda3\\envs\\dev\\lib\\site-packages\\scipy\\stats\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Sampling a grid of pints from the 2d latent space and decoding them to images\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.stats import sorm \n",
    "\n",
    "n = 15\n",
    "\n",
    "digit_size = 20\n",
    "\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi,yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        \n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        \n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "236b3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras \n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32 \n",
    "\n",
    "height = 32 \n",
    "\n",
    "width = 32 \n",
    "\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9c977693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The generator: GAN generator network\n",
    "\n",
    "gene_in = tensorflow.keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(128 * 16 * 16)(gene_in)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256,5, padding='same')(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = tensorflow.keras.models.Model(gene_in, x)\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "84d92bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_212 (Conv2D)          (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 4609      \n",
      "=================================================================\n",
      "Total params: 532,737\n",
      "Trainable params: 532,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The discriminator: The GAN discriminator network \n",
    "\n",
    "discriminator_in  = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_in)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x) # One dropout an important trick\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = tensorflow.keras.models.Model(discriminator_in, x)\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.RMSprop(\n",
    "    lr = 0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9b0c9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial network\n",
    "\n",
    "discriminator.trainableq = False\n",
    "\n",
    "gan_input = tensorflow.keras.Input(shape=(latent_dim,))\n",
    "\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "\n",
    "gan = tensorflow.keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = tensorflow.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4b31d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Implemetning GAN training \n",
    "\n",
    "import os \n",
    "\n",
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "(x_train, y_train), (_, _) = tensorflow.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec1f333b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 5000 but corresponding boolean dimension is 50000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2697878928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m x_train = x_train.reshape(\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     (height, width, channels)).astype('float32') / 255\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 5000 but corresponding boolean dimension is 50000"
     ]
    }
   ],
   "source": [
    "x_train  = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0], ) + \n",
    "    (height, width, channels)).astype('float32') / 255\n",
    "\n",
    "\n",
    "iteratios = 10000\n",
    "\n",
    "batch_size = 20 \n",
    "\n",
    "# save_dir = '' Specifies where you want to save genarated images\n",
    "\n",
    "start = 0 \n",
    "\n",
    "for step in range(iterations):\n",
    "    random_laten_vectors = np.random.normal(size=(batch_size,\n",
    "                                                 latent_dim))\n",
    "    \n",
    "    generated_images = generator.predict(random_laten_vectors)\n",
    "\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                            np.zeros((batch_size, 1))])\n",
    "    \n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                                  latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_laten_vectors, misleading_targets)\n",
    "    \n",
    "    \n",
    "    start += batch_size\n",
    "    \n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 1000 == 0:\n",
    "        gan.sample_weights('gan.h5')\n",
    "        \n",
    "        print('Discriminator loss:', d_loss)\n",
    "        \n",
    "        print('Adversarial loss:', d_loss)\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255, scale=False)\n",
    "        \n",
    "        img.save(os.path.join(save_dir,\n",
    "                             'generated_frog' + str(step) + '.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255, scale=False)\n",
    "        \n",
    "        img.save(os.path.jaoin(save_dir,\n",
    "                              'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c55577ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/3049768883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_input_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_input_features' is not defined"
     ]
    }
   ],
   "source": [
    "# To perform binary classificaiton\n",
    "# And stack of layers with a Dense layer witha single unit \n",
    "# and a sigmoid activation and use binary_crossentropy as the loss\n",
    "# Target should be either 0 or 1\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape= (num_input_features,)))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9e1edb55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/686131484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_input_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_input_features' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To perform single-label categorical classification (where each sample has exctly one class,\n",
    "no more),end your stack of layers with a Dense layer with a number of units equal to the number of classes,\n",
    "nd a softmax activation. If you targets are one-hot encoded, use categorical_corssentropy as the loss,\n",
    "if interges use sparse_categorical_crossentropy:\n",
    "\"\"\"\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features)))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edfcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5778b200",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1451230121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_input_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_input_features' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To perform multilabel categorical classification (where each sample can have several classes)\n",
    "    end your stack of layers with a Dense layer with a number of units equal to the number\n",
    "        of classes and a sigmoid activation, using binary_crossentropy as loss. TARGETS SHOULD BE K HOT ENCODED:\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features)))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss= 'binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c2e4e8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_input_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2012752518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_input_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_input_features' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To perform regressions toward a vector of continous values, end your stack of layers with a Dense layer witha number of \n",
    "\n",
    "units equal to the number of values youre trying to predict.\n",
    "\n",
    "(often a single one, such as the price of a house), and no activation.\n",
    "    Several losses can be used for regression, most commonly mean_squared_error (MSE) and mean_absolute_error (MAE):\n",
    "\"\"\"\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features)))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(num_values))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2fa135dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/1106323318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'remsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# convnets: Here's a typical image-classifcation network\n",
    "# (categorical classification)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.SeparableConv2D(32, 3, activation='relu',\n",
    "                                input_shape=(height, width, channels)))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64,3, activation='relu'))\n",
    "          \n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64,3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128,3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "          \n",
    "model.add(layers.SeparableConv2D(64,3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128,3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "          \n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "          \n",
    "model.add(layers.Dense(num_classes, activations='softmax'))\n",
    "          \n",
    "model.compile(optimizer='remsprop', loss='categorical_crossentropy')\n",
    "          \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d8473f07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_timesteps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2870059732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_timesteps' is not defined"
     ]
    }
   ],
   "source": [
    "# A single RNN later for binary classification of vactor sequences:\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.LSTM(32, input_shape=(num_timesteps, num_features)))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rsmprop', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "43ef1f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_timesteps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/99594435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.add(layers.LSTM(32, return_sequences=True,\n\u001b[1;32m----> 6\u001b[1;33m                      input_shape=(num_timesteps, num_features)))\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_timesteps' is not defined"
     ]
    }
   ],
   "source": [
    "# This is a stacked RNN layer for niabry classifaction of vector swquences:\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.LSTM(32, return_sequences=True,\n",
    "                     input_shape=(num_timesteps, num_features)))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.LSTM(32))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_corssentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651e683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
